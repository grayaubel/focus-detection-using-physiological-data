{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c88d17f",
   "metadata": {},
   "source": [
    "## Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5101d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as scisig\n",
    "from scipy.signal import welch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f6c1a",
   "metadata": {},
   "source": [
    "## Import WESAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        with open(os.path.join(main_path, self.name, self.name + '.pkl'), 'rb') as file:\n",
    "            self.data = pickle.load(file, encoding='latin1')\n",
    "        self.bvp = self.data['signal']['wrist']['BVP']\n",
    "        self.acc = self.data['signal']['wrist']['ACC']\n",
    "        self.eda = self.data['signal']['wrist']['EDA']\n",
    "        self.resp = self.data['signal']['chest']['Resp']\n",
    "        self.labels = self.data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e2091",
   "metadata": {},
   "source": [
    "## Define feature calculate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6db216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvp_to_hrv(bvp_signal, fs):\n",
    "    # Detect peaks\n",
    "    peaks, _ = scisig.find_peaks(bvp_signal, distance=int(fs * 0.4))\n",
    "\n",
    "    if len(peaks) < 3:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # คำนวณ IBI\n",
    "    ibi = np.diff(peaks) / fs * 1000 # ms\n",
    "    rr_diff = np.diff(ibi)\n",
    "    \n",
    "    # Time axis for interpolation\n",
    "    ibi_time = np.cumsum(ibi) / 1000 # sec\n",
    "    interp_time = np.arange(0, ibi_time[-1], 1/0.4)\n",
    "    ibi_interp = np.interp(interp_time, ibi_time, ibi)\n",
    "\n",
    "    # คำนวณ HR\n",
    "    hr = (60 * 1000) / ibi # bpm\n",
    "\n",
    "    # HRV  metrics\n",
    "    rmssd = np.sqrt(np.mean(rr_diff ** 2)) if len(rr_diff) > 0 else np.nan\n",
    "    sdnn = np.std(ibi) if len(ibi) > 1 else np.nan\n",
    "    pNN50 = np.sum(np.abs(rr_diff) > 50) / len(rr_diff) * 100 if len(rr_diff) > 0 else np.nan\n",
    "\n",
    "    # Frequency domain\n",
    "    f, pxx = welch(ibi_interp, fs=0.4)\n",
    "    lf = np.trapz(pxx[(f >= 0.04) & (f <= 0.15)], f[(f >= 0.04) & (f <= 0.15)])\n",
    "    hf = np.trapz(pxx[(f > 0.15) & (f <= 0.4)], f[(f > 0.15) & (f <= 0.4)])\n",
    "    lf_hf_ratio = lf / hf if hf != 0 else np.nan\n",
    "\n",
    "    # Alighn HR/IBI timestamsp (start at 2nd Beats)\n",
    "    timestamps = peaks[1:] / fs\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'timestamps': pd.to_datetime(timestamps, unit='s'),\n",
    "        'HR': hr,\n",
    "        'IBI': ibi,\n",
    "        'RMSSD': rmssd,\n",
    "        'SDNN': sdnn,\n",
    "        'pNN50': pNN50,\n",
    "        'lf/hf': lf_hf_ratio\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589abff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resp_features(resp_signal, fs):\n",
    "    peaks, _ = scisig.find_peaks(resp_signal, distance=fs * 2)\n",
    "    if len(peaks) < 2:\n",
    "        return {'RESP_rate': np.nan, 'RESP_regularity': np.nan}\n",
    "    \n",
    "    ibi = np.diff(peaks) / fs\n",
    "    resp_rate = 60 / np.mean(ibi) if np.mean(ibi) > 0 else np.nan\n",
    "    regularity = 1 / np.std(ibi) if np.std(ibi) > 0 else np.nan\n",
    "    return {\n",
    "        'RESP_rate': resp_rate,\n",
    "        'RESP_regularity': regularity\n",
    "        }\n",
    "\n",
    "def extract_eda_features(eda_signal):\n",
    "    x = np.arange(len(eda_signal))\n",
    "    slope = float(np.polyfit(x, eda_signal, 1)[0]) if len(eda_signal) > 1 else np.nan\n",
    "    return {\n",
    "        'EDA_mean': np.mean(eda_signal),\n",
    "        'EDA_std': np.std(eda_signal),\n",
    "        'EDA_slope': slope\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984277f",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74566a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling rates\n",
    "fs_dict = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'Resp': 700, 'label': 700}\n",
    "WINDOW_IN_SECONDS = 30\n",
    "\n",
    "# Save path\n",
    "save_path = \"../../data/processed/WESAD/feature_extracted_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb272655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(subject_id):\n",
    "    subject = SubjectData(main_path=\"../data/raw/WESAD\", subject_number=subject_id)\n",
    "\n",
    "    # Signals\n",
    "    bvp = subject.bvp.flatten()\n",
    "    acc = subject.acc\n",
    "    eda = subject.eda\n",
    "    resp = subject.resp\n",
    "    labels = subject.labels\n",
    "\n",
    "    # Windows\n",
    "    window_len = fs_dict['label'] * WINDOW_IN_SECONDS\n",
    "    total_len = len(labels)\n",
    "    n_windows = total_len // window_len\n",
    "\n",
    "    all_window = []\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        start = i * window_len\n",
    "        end = (i + 1) * window_len\n",
    "        \n",
    "        '''# label majority vote (optional, not used in clustering)\n",
    "        label_window = labels[start:end]\n",
    "        label = Counter(label_window).most_common(1)[0][0]'''\n",
    "\n",
    "        # majority vote label\n",
    "        label_window = labels[start:end]\n",
    "        label_window = [l for l in label_window if l in [1, 2, 3, 4]]\n",
    "        if len(label_window) == 0:\n",
    "            continue\n",
    "        label = Counter(label_window).most_common(1)[0][0]\n",
    "\n",
    "        # --- ACC ---\n",
    "        acc_window = acc[start * fs_dict['ACC'] // fs_dict['label']: end * fs_dict['ACC'] // fs_dict['label'], :]\n",
    "        if acc_window.shape[0] == 0: continue\n",
    "        acc_x, acc_y, acc_z = acc_window[:, 0], acc_window[:, 1], acc_window[:, 2]\n",
    "        net_acc = np.sqrt(acc_x ** 2 + acc_y ** 2 + acc_z ** 2)\n",
    "        acc_features = {\n",
    "            'ACC_x_mean': np.mean(acc_x),\n",
    "            'ACC_y_mean': np.mean(acc_y),\n",
    "            'ACC_z_mean': np.mean(acc_z),\n",
    "            'net_acc_mean': np.mean(net_acc),\n",
    "            'net_acc_std': np.std(net_acc)\n",
    "        }\n",
    "\n",
    "        # --- BVP / HRV ---\n",
    "        bvp_window = bvp[start * fs_dict['BVP'] // fs_dict['label']: end * fs_dict['BVP'] // fs_dict['label']]\n",
    "        hrv_df = bvp_to_hrv(bvp_window, fs_dict['BVP'])\n",
    "        if hrv_df.empty: continue\n",
    "        hrv_mean = hrv_df[['HR', 'IBI', 'RMSSD', 'SDNN', 'pNN50', 'lf/hf']].mean()\n",
    "\n",
    "        # --- EDA ---\n",
    "        eda_window = eda[start * fs_dict['EDA'] // fs_dict['label']: end * fs_dict['EDA'] // fs_dict['label']]\n",
    "        eda_features = extract_eda_features(eda_window)\n",
    "\n",
    "        # --- RESP ---\n",
    "        resp_window = resp[start * fs_dict['Resp'] // fs_dict['label']: end * fs_dict['Resp'] // fs_dict['label']]\n",
    "        if resp_window.ndim > 1:\n",
    "            resp_window = resp_window.flatten()\n",
    "        resp_features = extract_resp_features(resp_window, fs_dict['Resp'])\n",
    "\n",
    "        data = {\n",
    "            **acc_features,\n",
    "            **eda_features,\n",
    "            **resp_features,\n",
    "            'HR': hrv_mean['HR'],\n",
    "            'IBI': hrv_mean['IBI'],\n",
    "            'RMSSD': hrv_mean['RMSSD'],\n",
    "            'SDNN': hrv_mean['SDNN'],\n",
    "            'pNN50': hrv_mean['pNN50'],\n",
    "            'lf/hf': hrv_mean['lf/hf'],\n",
    "            'label': label,  # ไม่ใช้ในการ clustering โดยตรง แต่เก็บไว้ดู\n",
    "            'subject': subject_id\n",
    "        }\n",
    "        all_window.append(data)\n",
    "\n",
    "    df = pd.DataFrame(all_window)\n",
    "    df.to_csv(f'{save_path}/S{subject_id}.csv', index=False)\n",
    "    print(f'Subject {subject_id} processed with {len(df)} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d28f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_id in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]:\n",
    "    feature_extract(subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ad356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
